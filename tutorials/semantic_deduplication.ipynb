{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Semantic Deduplication with Model2Vec**\n",
    "\n",
    "In this tutorial, we’ll explore how Model2Vec can help identify duplicates in text data that traditional exact matching would miss. While exact matching works for identical texts, it fails to detect near-duplicates—documents that may differ slightly in wording but convey the same meaning. Using Model2Vec, we embed documents into vectors and measure their similarity. This allows us to catch both exact and semantic duplicates, improving the quality of our dataset. With Model2Vec’s speed and efficiency, we can very efficiently perform deduplication on large datasets, ensuring cleaner, more robust data for downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets model2vec reach numpy tqdm python-Levenshtein datasketch\n",
    "from datasets import load_dataset\n",
    "from model2vec import StaticModel\n",
    "from reach import Reach\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and dataset\n",
    "model = StaticModel.from_pretrained(\"minishlab/M2V_base_output\")\n",
    "ds = load_dataset(\"ag_news\")[\"train\"]\n",
    "texts = ds['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first try to find exact matches in the dataset as a baseline. Then, we will use Model2Vec to identify semantic duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seen = set()\n",
    "deduplicated_text_indices = np.array([i for i, text in enumerate(texts) if text not in seen and not seen.add(text)])\n",
    "len(deduplicated_text_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, we find no duplicate instances using exact string matching. Now, let's use Model2Vec to embed our documents and identify duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:02<00:00, 47.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode texts into embeddings\n",
    "embeddings = model.encode(texts, show_progressbar=True)\n",
    "embedding_matrix = np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to deduplicate embeddings\n",
    "def deduplicate(embedding_matrix: np.ndarray, threshold: float, batch_size: int = 1024) -> tuple[np.ndarray, dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Deduplicate embeddings and return the deduplicated indices and a mapping of removed indices to their corresponding original indices.\n",
    "    \n",
    "    :param embedding_matrix: The embeddings to deduplicate.\n",
    "    :param threshold: The similarity threshold to use for deduplication.\n",
    "    :param batch_size: The batch size to use for similarity computation.\n",
    "    :return: A tuple containing the deduplicated indices and a dictionary mapping removed indices to original indices.\n",
    "    \"\"\"\n",
    "    reach = Reach(vectors=embedding_matrix, items=[str(i) for i in range(len(embedding_matrix))])\n",
    "    \n",
    "    # Find similar documents\n",
    "    is_duplicate = np.zeros(len(embedding_matrix), dtype=bool)\n",
    "    duplicate_to_original_mapping = {}\n",
    "\n",
    "    results = reach.threshold(\n",
    "        [str(i) for i in range(len(embedding_matrix))], \n",
    "        threshold=threshold, \n",
    "        batch_size=batch_size, \n",
    "        show_progressbar=True\n",
    "    )\n",
    "    \n",
    "    # Process duplicates\n",
    "    for i, similar_items in tqdm(enumerate(results), total=len(results)):\n",
    "        if is_duplicate[i]:\n",
    "            continue  # Skip already marked duplicates\n",
    "\n",
    "        # Similar items are returned as (index, score), we are only interested in the index\n",
    "        similar_indices = [int(item[0]) for item in similar_items if int(item[0]) != i]\n",
    "        \n",
    "        # Mark similar documents as duplicates and map them to the original\n",
    "        for sim_idx in similar_indices:\n",
    "            is_duplicate[sim_idx] = True\n",
    "            duplicate_to_original_mapping[sim_idx] = i  # Map duplicate to original\n",
    "\n",
    "    deduplicated_indices = np.where(~is_duplicate)[0]\n",
    "\n",
    "    return deduplicated_indices, duplicate_to_original_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 117/118 [00:24<00:00,  4.77it/s]\n",
      "100%|██████████| 120000/120000 [00:00<00:00, 945566.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "118769"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deduplicate (with a high threshold)\n",
    "deduplicated_indices, duplicate_to_original_mapping = deduplicate(embedding_matrix, threshold=0.99)\n",
    "len(deduplicated_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Model2Vec, we find > 1000 duplicates with a very high threshold, in < 30 seconds. Now, let's look at a few examples to see if these are indeed duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\about the economy and the outlook for earnings are expected to\\hang over the stock market next week during the depth of the\\summer doldrums.\n",
      "Duplicate text: Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\about the economy and the outlook for earnings are expected to\\hang over the stock market this week during the depth of the\\summer doldrums.\n",
      "--------------------------------------------------\n",
      "Original text: Oil and Economy Cloud Stocks' Outlook  NEW YORK (Reuters) - Soaring crude prices plus worries  about the economy and the outlook for earnings are expected to  hang over the stock market next week during the depth of the  summer doldrums.\n",
      "Duplicate text: Oil and Economy Cloud Stocks' Outlook  NEW YORK (Reuters) - Soaring crude prices plus worries  about the economy and the outlook for earnings are expected to  hang over the stock market this week during the depth of the  summer doldrums.\n",
      "--------------------------------------------------\n",
      "Original text: Phelps, Thorpe Advance in 200 Freestyle ATHENS, Greece - Michael Phelps took care of qualifying for the Olympic 200-meter freestyle semifinals Sunday, and then found out he had been added to the American team for the evening's 400 freestyle relay final. Phelps' rivals Ian Thorpe and Pieter van den Hoogenband and teammate Klete Keller were faster than the teenager in the 200 free preliminaries...\n",
      "Duplicate text: Phelps, Thorpe Advance in 200 Freestyle ATHENS, Greece - Michael Phelps took care of qualifying for the Olympic 200-meter freestyle semifinals Sunday, and then found out he had been added to the American team for the evening's 400 freestyle relay final.    Phelps' rivals Ian Thorpe and Pieter van den Hoogenband and teammate Klete Keller were faster than the teenager in the 200 free preliminaries...\n",
      "--------------------------------------------------\n",
      "Original text: Government Spending Up Sharply Locally  Federal procurement spending in the Washington area rose last year at its highest rate since the 1980s, according to a study to be released today, creating tens of thousands of jobs and increasing economic growth disproportionately in Northern Virginia.\n",
      "Duplicate text: Government Spending Up Sharply Locally Federal procurement spending in the Washington area rose last year at its highest rate since the 1980s, according to a study to be released today, creating tens of thousands of jobs and increasing economic growth disproportionately in Northern Virginia.\n",
      "--------------------------------------------------\n",
      "Original text: F.B.I. Goes Knocking for Political Troublemakers The F.B.I. has been questioning demonstrators in an effort to forestall violent protests at the Republican National Convention.\n",
      "Duplicate text: F.B.I. Goes Knocking for Political Troublemakers The F.B.I. has been questioning demonstrators in an effort to forestall violent protests at the Republican convention.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Show a few duplicates with their originals\n",
    "num_examples = 5\n",
    "for duplicate_idx, original_idx in list(duplicate_to_original_mapping.items())[:num_examples]:\n",
    "    print(f\"Original text: {texts[original_idx]}\")\n",
    "    print(f\"Duplicate text: {texts[duplicate_idx]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The found texts do indeed seem to be duplicates, nice! In a normal workflow where we use Model2Vec to embed our documents, deduplication our training corpus is essentially free. This gives us an easy to use, easy to integrate, fast alternative to other methods such as MinHash."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
