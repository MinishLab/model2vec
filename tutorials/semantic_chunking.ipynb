{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Semantic Chunking with Chonkie and Model2Vec**\n",
    "\n",
    "Semantic chunking is a task of identifying the semantic boundaries of a piece of text. In this tutorial, we will use the [Chonkie](https://github.com/bhavnicksm/chonkie) library to perform semantic chunking on the book War and Peace. Chonkie is a library that provides a lightweight and fast solution to semantic chunking using pre-trained models. It supports our [potion models](https://huggingface.co/collections/minishlab/potion-6721e0abd4ea41881417f062) out of the box, which we will be using in this tutorial.\n",
    "\n",
    "After chunking our text, we will be using [Vicinity](https://github.com/MinishLab/vicinity), a lightweight nearest neighbors library, to create an index of our chunks and query them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the necessary libraries\n",
    "!pip install datasets model2vec numpy tqdm vicinity\n",
    "\n",
    "# Import the necessary libraries\n",
    "import random \n",
    "import re\n",
    "import requests\n",
    "from time import perf_counter\n",
    "from chonkie import SDPMChunker\n",
    "from model2vec import StaticModel\n",
    "from vicinity import Vicinity\n",
    "\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading and pre-processing**\n",
    "\n",
    "First, we will download War and Peace and apply some basic pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for War and Peace on Project Gutenberg\n",
    "url = \"https://www.gutenberg.org/files/2600/2600-0.txt\"\n",
    "\n",
    "# Download the book\n",
    "response = requests.get(url)\n",
    "book_text = response.text\n",
    "\n",
    "def preprocess_text(text: str, min_length: int = 5):\n",
    "    \"\"\"Basic text preprocessing function.\"\"\"\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.replace(\"\\r\", \" \")\n",
    "    sentences = re.findall(r'[^.!?]*[.!?]', text)\n",
    "    # Filter out sentences shorter than the specified minimum length\n",
    "    filtered_sentences = [sentence.strip() for sentence in sentences if len(sentence.split()) >= min_length]\n",
    "    # Recombine the filtered sentences\n",
    "    return ' '.join(filtered_sentences)\n",
    "\n",
    "# Preprocess the text\n",
    "book_text = preprocess_text(book_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chunking with Chonkie**\n",
    "\n",
    "Next, we will use Chonkie to chunk our text into semantic chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 6148\n",
      "Time taken: 2.2917541670030914\n"
     ]
    }
   ],
   "source": [
    "# Initialize a SemanticChunker from Chonkie with the potion-base-8M model\n",
    "chunker = SDPMChunker(\n",
    "    embedding_model=\"minishlab/potion-base-8M\",\n",
    "    similarity_threshold=0.3,\n",
    "    skip_window=5,\n",
    "    chunk_size = 256\n",
    ")\n",
    "\n",
    "# Chunk the text\n",
    "time = perf_counter()\n",
    "chunks = chunker.chunk(book_text)\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "print(f\"Time taken: {perf_counter() - time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it, we chunked the entirety of War and Peace in ~2 seconds. Not bad! Let's look at some example chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ”    “I can’t think what the servants are about,” said the countess, turning  to her husband. \n",
      "\n",
      " He was received in the best houses not merely as a doctor, but  as an equal. \n",
      "\n",
      " “That’s enough, Natásha,” said Sónya. \n",
      "\n",
      " Pierre did not catch what they were saying, but knew they were talking  about him. He reddened and turned away. “Well, now to the health of handsome women! ” said Dólokhov, and  with a serious expression, but with a smile lurking at the corners of  his mouth, he turned with his glass to Pierre. “Here’s to the health of lovely women, Peterkin—and their  lovers! Pierre, with downcast eyes, drank out of his glass without looking at  Dólokhov or answering him. The footman, who was distributing leaflets  with Kutúzov’s cantata, laid one before Pierre as one of the  principal guests. He was just going to take it when Dólokhov, leaning  across, snatched it from his hand and began reading it. Pierre looked  at Dólokhov and his eyes dropped, the something terrible and monstrous  that had tormented him all dinnertime rose and took possession of him. He leaned his whole massive body across the table. “How dare you take it? Hearing that cry and seeing to whom it was addressed, Nesvítski and the  neighbor on his right quickly turned in alarm to Bezúkhov. \n",
      "\n",
      " The  whole street was full of clouds of black smoke. Tongues of flame here  and there broke through that cloud. A great number of people crowded in  front of the conflagration. In the middle of the street stood a French  general saying something to those around him. Pierre, accompanied by the  maid, was advancing to the spot where the general stood, but the French  soldiers stopped him. ” * cried a voice. ”      “This way, uncle,” cried the girl. “We’ll pass through the side street,  by the Nikúlins’! ”    Pierre turned back, giving a spring now and then to keep up with her. She ran across the street, turned down a side street to the left, and,  passing three houses, turned into a yard on the right. “It’s here, close by,” said she and, running across the yard, opened a  gate in a wooden fence and, stopping, pointed out to him a small wooden  wing of the house, which was burning brightly and fiercely. One of its  sides had fallen in, another was on fire, and bright flames issued from  the openings of the windows and from under the roof. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a few example chunks\n",
    "for _ in range(5):\n",
    "    chunk = random.choice(chunks)\n",
    "    print(chunk.text, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those look good. Next, let's create a vector search index with Vicinity and Model2Vec.\n",
    "\n",
    "**Creating a vector search index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1.5817922909918707\n"
     ]
    }
   ],
   "source": [
    "# Initialize an embedding model and encode the chunk texts\n",
    "time = perf_counter()\n",
    "model = StaticModel.from_pretrained(\"minishlab/potion-base-8M\")\n",
    "chunk_texts = [chunk.text for chunk in chunks]\n",
    "chunk_embeddings = model.encode(chunk_texts)\n",
    "\n",
    "# Create a Vicinity instance\n",
    "vicinity = Vicinity.from_vectors_and_items(vectors=chunk_embeddings, items=chunk_texts)\n",
    "print(f\"Time taken: {perf_counter() - time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! We embedded all our chunks and created an in index in ~1.5 seconds. Now that we have our index, let's query it with some queries.\n",
    "\n",
    "**Querying the index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Emperor Napoleon\n",
      "--------------------------------------------------\n",
      " In 1808 the Emperor Alexander went to Erfurt for a fresh interview with  the Emperor Napoleon, and in the upper circles of Petersburg there was  much talk of the grandeur of this important meeting. CHAPTER XXII    In 1809 the intimacy between “the world’s two arbiters,” as  Napoleon and Alexander were called, was such that when Napoleon declared  war on Austria a Russian corps crossed the frontier to co-operate with  our old enemy Bonaparte against our old ally the Emperor of Austria, and  in court circles the possibility of marriage between Napoleon and one  of Alexander’s sisters was spoken of. \n",
      "\n",
      " ) “It’s in the Emperor’s  service. \n",
      "\n",
      " “The day before yesterday it was ‘Napoléon, France,  bravoure’; yesterday, ‘Alexandre, Russie, grandeur. ’ One day our  Emperor gives it and next day Napoleon. Tomorrow our Emperor will send  a St. \n",
      "\n",
      "Query: The battle of Austerlitz\n",
      "--------------------------------------------------\n",
      " On the first arrival of the news of the battle of Austerlitz, Moscow had  been bewildered. \n",
      "\n",
      " That  city is taken; the Russian army suffers heavier losses than the opposing  armies had suffered in the former war from Austerlitz to Wagram. \n",
      "\n",
      " Behave as you did at  Austerlitz, Friedland, Vítebsk, and Smolénsk. \n",
      "\n",
      "Query: Paris\n",
      "--------------------------------------------------\n",
      " A man who doesn’t know Paris  is a savage. You can tell a Parisian two leagues off. Paris is Talma, la  Duchénois, Potier, the Sorbonne, the boulevards,” and noticing that  his conclusion was weaker than what had gone before, he added quickly:  “There is only one Paris in the world. You have been to Paris and have  remained Russian. \n",
      "\n",
      " Well, what is Paris saying? \n",
      "\n",
      " Paris would have been the capital of the world, and the French the envy  of the nations! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "queries = [\"Emperor Napoleon\", \"The battle of Austerlitz\", \"Paris\"]\n",
    "for query in queries:\n",
    "    print(f\"Query: {query}\\n{'-' * 50}\")\n",
    "    query_embedding = model.encode(query)\n",
    "    results = vicinity.query(query_embedding, k=3)[0]\n",
    "\n",
    "    for result in results:\n",
    "        print(result[0], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These indeed look like relevant chunks, nice! That's it for this tutorial. We were able to chunk, index, and query War and Peace in about 3.5 seconds using Chonkie, Vicinity, and Model2Vec. Lightweight and fast, just how we like it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
